{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Connecting our google drive"
      ],
      "metadata": {
        "id": "CNIPYq-aV-iq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "344eTxG0Fsxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f130af71-7402-48c3-83fa-34c62af94612"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installing the transformer module"
      ],
      "metadata": {
        "id": "ysAs0245WG1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bE-497waNJeC",
        "outputId": "6ac730a0-79ae-4864-e347-cac6295ff4f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the required modules"
      ],
      "metadata": {
        "id": "kxCe0agcWMQZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the required modules\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import string\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "import json\n",
        "import nltk\n",
        "import joblib\n",
        "from sklearn.feature_extraction.text import CountVectorizer , TfidfVectorizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from transformers import AutoTokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image\n",
        "import os\n",
        "import time\n",
        "\n"
      ],
      "metadata": {
        "id": "S37YvbEjGRTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5OrUXSKVYiYq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for the colab to take photo on demand"
      ],
      "metadata": {
        "id": "dsgz8W2kWRlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#code for taking snaps\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import base64\n",
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    # Load the Haar Cascade classifier for face detection\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "    js = Javascript('''\n",
        "        async function takePhoto(quality) {\n",
        "            const div = document.createElement('div');\n",
        "            const video = document.createElement('video');\n",
        "            video.style.display = 'block';\n",
        "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "            document.body.appendChild(div);\n",
        "            div.appendChild(video);\n",
        "            video.srcObject = stream;\n",
        "            await video.play();\n",
        "\n",
        "            // Resize the output to fit the video element.\n",
        "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
        "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
        "\n",
        "            const canvas = document.createElement('canvas');\n",
        "            canvas.width = video.videoWidth;\n",
        "            canvas.height = video.videoHeight;\n",
        "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "            stream.getVideoTracks()[0].stop();\n",
        "            div.remove();\n",
        "            return canvas.toDataURL('image/jpeg', quality);\n",
        "        }\n",
        "        ''')\n",
        "    display(js)\n",
        "\n",
        "    # Get photo data\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    # Convert the base64 image data to a numpy array\n",
        "    img_data = data.split(',')[1]\n",
        "    img_array = np.frombuffer(base64.b64decode(img_data), np.uint8)\n",
        "    # Decode the numpy array to an OpenCV image\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
        "\n",
        "    # Convert the image to grayscale if it has only one channel\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Grayscale img\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    print(gray.shape)\n",
        "    # Get face bounding box coordinates using Haar Cascade\n",
        "    faces = face_cascade.detectMultiScale(gray)\n",
        "    # Draw face bounding box on image\n",
        "    for (x, y, w, h) in faces:\n",
        "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 0), 2)\n",
        "    # Save image\n",
        "    cv2.imwrite(filename, img)\n",
        "\n",
        "    #return filename\n",
        "\n"
      ],
      "metadata": {
        "id": "7ogyFszfyy_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization and the creation of dataframe of the dataset for visualisation"
      ],
      "metadata": {
        "id": "mUTJHcCRWuxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#vectorization of text\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/final_version/nlp dataset/train_for_nlp.csv.csv\")\n",
        "\n",
        "target_frequency = df['Emotions'].value_counts().mean()\n",
        "\n",
        "undersampled_df = pd.DataFrame(columns=['Emotions', 'Text'])\n",
        "\n",
        "for emotion in df['Emotions'].unique():\n",
        "    emotion_data = df[df['Emotions'] == emotion]\n",
        "    num_samples = min(int(target_frequency), len(emotion_data))\n",
        "    sampled_rows = emotion_data.sample(n=num_samples, random_state=42)\n",
        "    undersampled_df = undersampled_df.append(sampled_rows)\n",
        "\n",
        "\n",
        "result_df = undersampled_df.sample(frac=1, random_state=42)\n",
        "\n",
        "\n",
        "xfeatures = result_df['Text']\n",
        "ylables = result_df['Emotions']\n",
        "\n",
        "#visualisaion\n",
        "\n",
        "undersampled_df['Emotions'].value_counts().plot(kind = \"bar\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 707
        },
        "id": "amEeCvSoJcz5",
        "outputId": "8ad13f91-0c38-43ac-c631-a6892fffe091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n",
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n",
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n",
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n",
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n",
            "<ipython-input-4-12ba9d6860a8>:12: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
            "  undersampled_df = undersampled_df.append(sampled_rows)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vectorization"
      ],
      "metadata": {
        "id": "QMrmLc5cW7Vb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv = CountVectorizer()\n",
        "x4 = cv.fit_transform(xfeatures)"
      ],
      "metadata": {
        "id": "i_YR8qSVXjC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the nlp models\n",
        "nlp_model = joblib.load('/content/drive/MyDrive/final_version/nlp model /emotion_classifier_lr_model.pkl')\n"
      ],
      "metadata": {
        "id": "tQnYvM0MIsXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get the emotion from text\n",
        "def predict_emotion(text , model):\n",
        "  myvect = cv.transform(text).toarray()\n",
        "  prediction = model.predict(myvect)\n",
        "  #print(prediction,\"\\n\")\n",
        "  pred_prob = (model.predict_proba(myvect))\n",
        "  #print(pred_prob,\"\\n\")\n",
        "  pred_percentage_for_all = dict(zip(model.classes_,pred_prob[0]))\n",
        "  return prediction[0]"
      ],
      "metadata": {
        "id": "vE2uYa8NKSm6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "My0bGDCWKabn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzrl7r5JMRsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function for finding the max occuring of the list"
      ],
      "metadata": {
        "id": "ovMf_nYKMS8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def max_occuring_element(lst):\n",
        "    # Count the occurrences of each element in the list\n",
        "    count_dict = Counter(lst)\n",
        "\n",
        "    # Find the element with the maximum occurrence\n",
        "    max_occurrence = max(count_dict.values())\n",
        "    max_occuring_elements = [element for element, count in count_dict.items() if count == max_occurrence]\n",
        "\n",
        "    return max_occuring_elements\n",
        "\n"
      ],
      "metadata": {
        "id": "MljMp0_JN4AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading our saved model for image emotion processing."
      ],
      "metadata": {
        "id": "tpAhy7AoYAKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading the emotional recognition model\n",
        "emotion_model = load_model('/content/drive/MyDrive/final_version/emotion recogniton model/visualmodel_2.h5')"
      ],
      "metadata": {
        "id": "LEkXarePI0L0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(emotion_model)"
      ],
      "metadata": {
        "id": "SpUXqltqEMg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code for the decoading of emotion"
      ],
      "metadata": {
        "id": "fSl8Y9BbY7cj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_to_text = {0:'anger', 1: 'contempt',2:'disgust', 3:'fear', 4:'happy',5:'neutral', 6: 'sad', 7: 'surprise'}"
      ],
      "metadata": {
        "id": "F8A1KK740ERu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing for the taken image from webcam"
      ],
      "metadata": {
        "id": "8viVg8aJZEON"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#image pre processing\n",
        "def pre_processing(filename):\n",
        "\n",
        "    image = Image.open(filename)\n",
        "    #image_grey = image.convert('L')\n",
        "    # procesed_image = image.resize((224,224))\n",
        "    # qq = np.array(procesed_image)\n",
        "    #qq =np.expand_dims(qq,axis = -1)\n",
        "\n",
        "    procesed_image = image.resize((224,224))\n",
        "    qq = np.array(procesed_image)\n",
        "\n",
        "\n",
        "    single_image_batch = np.expand_dims(qq, axis=0)\n",
        "    z = emotion_model.predict(single_image_batch).argmax()\n",
        "\n",
        "    return label_to_text[z]\n"
      ],
      "metadata": {
        "id": "Nwoe4Uy3zmEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emotion_image_detection(counter_var):\n",
        "  file_name = \"/content/drive/MyDrive/final_version/photo_detect/image{}.jpg\".format(counter_var)\n",
        "  take_photo(filename = file_name)\n",
        "  value = pre_processing(file_name)\n",
        "  return value\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vZqGvNC20kaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8CDOjfRo1pUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to get the promiment emotion out if the lit\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def max_occuring_element(lst):\n",
        "    # Count the occurrences of each element in the list\n",
        "    count_dict = Counter(lst)\n",
        "\n",
        "    # Find the element with the maximum occurrence\n",
        "    max_occurrence = max(count_dict.values())\n",
        "    max_occuring_elements = [element for element, count in count_dict.items() if count == max_occurrence]\n",
        "\n",
        "    return max_occuring_elements\n"
      ],
      "metadata": {
        "id": "dqAHbZcGxWjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The chat bot model"
      ],
      "metadata": {
        "id": "BZZvDhb3ZQYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from difflib import get_close_matches\n",
        "\n",
        "def load_knowlegde_base(path_file:str)-> dict:\n",
        "  with open(path_file , 'r' ) as file:\n",
        "    data: dict = json.load(file)\n",
        "  return data\n",
        "\n",
        "def save_knowledge_base(path_file : str , data :dict):\n",
        "  with open(path_file , 'w') as file:\n",
        "    json.dump(data , file , indent = 2)\n",
        "\n",
        "def find_best_match(user_question: str , questions: list[str]) -> str|None:\n",
        "  matches : list = get_close_matches(user_question ,  questions , n = 1 , cutoff\n",
        "   = 0.6)\n",
        "  return matches[0] if matches else None\n",
        "\n",
        "def get_answer_for_question(question: str , knowledge_base : dict) -> str | None:\n",
        "  for q in knowledge_base['question']:\n",
        "    if q['question'] == question:\n",
        "      return q['answer']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DEJIRmAnB0Wd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "def chatbot():\n",
        "  knowledge_base :dict = load_knowlegde_base('/content/drive/MyDrive/final_version/intent for chatbot/knowlede_base.json')\n",
        "\n",
        "\n",
        "#exiting quotes\n",
        "  exits = [\"Goodbye for now, as I welcome the mysteries that the future holds\",\n",
        "         \"In parting, I take with me the lessons learned and the strength gained.\",\n",
        "         \"As I bid farewell, I carry the warmth of cherished moments in my heart.\",\n",
        "         \"Like a shooting star, I leave a trail of dreams behind on my onward journey.\"]\n",
        "\n",
        "\n",
        "  global emotion_list\n",
        "  emotion_list = list()\n",
        "\n",
        "  global emotion_list_visual\n",
        "  emotion_list_visual = list()\n",
        "\n",
        "  counter_variable = 0\n",
        "\n",
        "  input_shape = 6\n",
        "  image_file_list = []\n",
        "\n",
        "\n",
        "  while True:\n",
        "    user_input : str = input(\"YOU ->> \")\n",
        "    emotion_list.append(predict_emotion([user_input],nlp_model))\n",
        "    emotion_list_visual.append(emotion_image_detection(counter_variable))\n",
        "\n",
        "    counter_variable = counter_variable + 1\n",
        "\n",
        "\n",
        "    if user_input.lower() == 'goodbye':\n",
        "      print(\"Sagittarias ->> :\" ,exits[random.randint(0,3)])\n",
        "      break\n",
        "    best_match :str| None = find_best_match(user_input ,[ q['question'] for q in knowledge_base['question']])\n",
        "\n",
        "    if best_match:\n",
        "      answer : str = get_answer_for_question(best_match , knowledge_base)\n",
        "      print(f'Sagittarias ->> : {answer}')\n",
        "\n",
        "    else:\n",
        "      print(\"Sagittarias : I do not know the answer .  Can you teach me ? \")\n",
        "      new_answer: str = input(' ** Type the answer or skip ** ->')\n",
        "\n",
        "      if new_answer.lower() != 'skip':\n",
        "        knowledge_base['question'].append({\"question\" : user_input , \"answer\": new_answer})\n",
        "        save_knowledge_base('/content/drive/MyDrive/final_version/intent for chatbot/knowlede_base.json' , knowledge_base)\n",
        "        print('bot : Thank you learnt it')\n"
      ],
      "metadata": {
        "id": "1wk8BM0FB98y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  chatbot()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "0LfVSGwUDRLB",
        "outputId": "04bfcbc9-3db4-4ea4-dced-9697ca53f4f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOU ->> hello\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
              "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 640)\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "Sagittarias ->> : What is up\n",
            "YOU ->> nice \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
              "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 640)\n",
            "1/1 [==============================] - 0s 387ms/step\n",
            "Sagittarias : I do not know the answer .  Can you teach me ? \n",
            " ** Type the answer or skip ** ->do tell\n",
            "bot : Thank you learnt it\n",
            "YOU ->> nice\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
              "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 640)\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "Sagittarias ->> : do tell\n",
            "YOU ->> i went to dakhineswer today\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
              "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(480, 640)\n",
            "1/1 [==============================] - 0s 222ms/step\n",
            "Sagittarias ->> : wao thats great u must have learnt many new things\n",
            "YOU ->> goodbye\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        async function takePhoto(quality) {\n",
              "            const div = document.createElement('div');\n",
              "            const video = document.createElement('video');\n",
              "            video.style.display = 'block';\n",
              "            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "            document.body.appendChild(div);\n",
              "            div.appendChild(video);\n",
              "            video.srcObject = stream;\n",
              "            await video.play();\n",
              "\n",
              "            // Resize the output to fit the video element.\n",
              "            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "            // Wait for a short delay to ensure the video stream stabilizes (you can adjust the delay if needed).\n",
              "            await new Promise((resolve) => setTimeout(resolve, 200));\n",
              "\n",
              "            const canvas = document.createElement('canvas');\n",
              "            canvas.width = video.videoWidth;\n",
              "            canvas.height = video.videoHeight;\n",
              "            canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "            stream.getVideoTracks()[0].stop();\n",
              "            div.remove();\n",
              "            return canvas.toDataURL('image/jpeg', quality);\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(480, 640)\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "Sagittarias ->> : As I bid farewell, I carry the warmth of cherished moments in my heart.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_list"
      ],
      "metadata": {
        "id": "P2tSZFoxTpF-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3178d010-7b3c-4d67-a3d1-f52b5c6e84f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['joy', 'joy', 'joy', 'joy', 'joy']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotion_list_visual"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXT-p5Hy4o0A",
        "outputId": "b319907b-887b-41c5-a06b-f7cfa01e785e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['contempt', 'neutral', 'neutral', 'neutral', 'neutral']"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_occuring_element(emotion_list)[0] and max_occuring_element(emotion_list_visual)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "DkRC82Q4YWUt",
        "outputId": "5e49c81f-dd73-43ca-fc06-febfdd5fc13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_occuring_element(emotion_list_visual)[0] or  max_occuring_element(emotion_list)[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "QnjpYeoDYZsb",
        "outputId": "da52e17e-0e08-4f97-b1f8-45657e3227c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'neutral'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print( max_occuring_element(emotion_list)[0]   )\n",
        "print( max_occuring_element(emotion_list_visual)[0] )\n",
        "\n",
        "if (max_occuring_element(emotion_list)[0] and max_occuring_element(emotion_list_visual)[0] ) in ['sad','sadness' , 'contempt' , 'anger' ,'disgust']:\n",
        "\n",
        "  print(\"\"\" I'm sorry to that you're sad. Remember that you're not alone, \\n\n",
        "and it's okay to have these emotions. If you'd like, I'm here to listen and chat with you. \\n\n",
        "Sometimes, expressing your feelings can help lighten the load. \\n\n",
        "Just know that it's alright to reach out for support when you need it.\"\"\")\n",
        "\n",
        "elif (  max_occuring_element(emotion_list_visual)[0] or  max_occuring_element(emotion_list)[0]   )  in [ 'happy' , 'surprise' , 'joy','neutral' ]:\n",
        "\n",
        "  print(\"\"\"Congratulations on being in such a great mood!\\n\n",
        "😄 Your positivity is truly contagious and it's wonderful to see your upbeat energy.\\n\n",
        "Keep spreading those good vibes and making the world a brighter place.\\n\n",
        "If there's anything you'd like to chat about or share, I'm here to listen and engage in some positive conversation! 🌞 \"\"\")\n",
        "\n",
        "else:\n",
        "  print(\" Its nice talking to you good bye see you later \")\n"
      ],
      "metadata": {
        "id": "Nf9hLY33xcS3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5082a55d-0b20-4d80-9a63-c57b37707a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "joy\n",
            "neutral\n",
            "Congratulations on being in such a great mood!\n",
            "\n",
            "😄 Your positivity is truly contagious and it's wonderful to see your upbeat energy.\n",
            "\n",
            "Keep spreading those good vibes and making the world a brighter place.\n",
            "\n",
            "If there's anything you'd like to chat about or share, I'm here to listen and engage in some positive conversation! 🌞 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# label_to_text = {0:'anger', 1: 'contempt',2:'disgust', 3:'fear', 4:'happy',5:'neutral', 6: 'sad', 7: 'surprise'}\n",
        "\n",
        "#chatbot code\n",
        "import random\n",
        "\n",
        "#exiting quotes\n",
        "exits = [\"Goodbye for now, as I welcome the mysteries that the future holds\",\n",
        "         \"In parting, I take with me the lessons learned and the strength gained.\",\n",
        "         \"As I bid farewell, I carry the warmth of cherished moments in my heart.\",\n",
        "         \"Like a shooting star, I leave a trail of dreams behind on my onward journey.\"]\n",
        "\n",
        "emotion_list = []\n",
        "emotion_list_visual = []\n",
        "\n",
        "counter_variable = 0\n",
        "\n",
        "input_shape = 6\n",
        "image_file_list = []\n",
        "#chatbot loop\n",
        "while True:\n",
        "\n",
        "  text_p = []\n",
        "  prediction_input = input(\"you... :-->\")\n",
        "  emotion_list.append(predict_emotion([prediction_input],nlp_model))\n",
        "  emotion_list_visual.append(emotion_image_detection(counter_variable))\n",
        "\n",
        "  counter_variable = counter_variable + 1\n",
        "\n",
        "\n",
        "\n",
        "  if prediction_input == \"goodbye\":\n",
        "    print(\"Dell :\" ,exits[random.randint(0,3)])\n",
        "    break\n",
        "  prediction_input = [letter.lower() for letter in prediction_input if letter not in string.punctuation]\n",
        "  prediction_input = ''.join(prediction_input)\n",
        "  text_p.append(prediction_input)\n",
        "\n",
        "  prediction_input = tokenizer.texts_to_sequences(text_p)\n",
        "  prediction_input = np.array(prediction_input).reshape(-1)\n",
        "  prediction_input = pad_sequences([prediction_input],input_shape )\n",
        "\n",
        "\n",
        "  output = chatbot.predict(prediction_input)\n",
        "  output = output.argmax()\n",
        "\n",
        "  response_tag = le.inverse_transform([output])[0]\n",
        "\n",
        "  print(\"Dell : \",random.choice(responses[response_tag]))\n",
        "\n",
        "\n",
        "print(max_occuring_element(emotion_list))\n",
        "print(max_occuring_element(emotion_list_visual))\n",
        "if max_occuring_element(emotion_list) or max_occuring_element(emotion_list_visual) in ['sad' , 'contempt' , 'anger' ,'disgus']:\n",
        "  print(\"i think you should listen to calmimg songs \")\n",
        "else:\n",
        "  print(\"here are some songs for you \")"
      ],
      "metadata": {
        "id": "N9VhsLOyK6lo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}